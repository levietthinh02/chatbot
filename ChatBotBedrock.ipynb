{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvRbcpiOgtfa1+VkI3nHPv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9kkdkoWLeiX",
        "outputId": "f1894a11-15e7-4c6a-9f78-a09f0b486c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet \\\n",
        "  boto3 \\\n",
        "  botocore \\\n",
        "  awscli"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "ZjZ9IeAvXcNf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input your AWS Access Key ID\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass(\"Your AWS Access Key ID:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6x2m-LXaMxg",
        "outputId": "388f5c46-d12c-4bfe-e508-59c89afdb6fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Access Key ID:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input your AWS Secret Access Key\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass(\"Your AWS Secret Access Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIO92rfvaU8O",
        "outputId": "3f964192-6ef3-4f85-8774-397672d4c68a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Secret Access Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Bedrock Runtime client in the AWS Region you want to use.\n",
        "client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
        "\n",
        "# Set the maximum length of the response.\n",
        "max_tokens = 512\n",
        "\n",
        "# Set the model ID, e.g., Titan Text Premier.\n",
        "model_id = \"meta.llama3-1-405b-instruct-v1:0\"\n",
        "\n",
        "# Set the characteristics of the bot.\n",
        "system_message = \"\"\"[INST]You are a a very intelligent bot with exceptional critical thinking.[/INST]\"\"\"\n",
        "\n",
        "conversation = []\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "      user_message = input(\"\\nEnter a prompt (empty to quit):\").strip()\n",
        "      if user_message:\n",
        "          conversation.append({\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [{\"text\": system_message + user_message}],\n",
        "          })\n",
        "\n",
        "          # Send the message to the model, using a basic inference configuration.\n",
        "          response = client.converse(\n",
        "              modelId=model_id,\n",
        "              messages=conversation,\n",
        "              inferenceConfig={\"maxTokens\":max_tokens,\"temperature\":0.5,\"topP\":0.9},\n",
        "              additionalModelRequestFields={}\n",
        "          )\n",
        "\n",
        "          # Extract and print the response text.\n",
        "          response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
        "          print(response_text + \"\\n\")\n",
        "\n",
        "          conversation.append({\n",
        "              \"role\": \"assistant\",\n",
        "              \"content\": [{\"text\": response_text}],\n",
        "          })\n",
        "\n",
        "      else:\n",
        "          print(\"[Exited]\")\n",
        "          break\n",
        "\n",
        "  except (ClientError, Exception) as e:\n",
        "      print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
        "      exit(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXn0iadvdS7s",
        "outputId": "5691bb20-92cf-4bf1-9510-fc4f7ce213ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter a prompt (empty to quit):Hello\n",
            "\n",
            "\n",
            "Hello! It's a pleasure to interact with you. I'm excited to engage in a conversation that challenges my critical thinking abilities. What topic would you like to discuss? Would you like to explore a philosophical concept, analyze a complex issue, or perhaps tackle a logical puzzle? I'm all ears (or rather, all text). Let's dive into a stimulating conversation!\n",
            "\n",
            "\n",
            "Enter a prompt (empty to quit):What is your name?\n",
            "\n",
            "\n",
            "A question that gets to the heart of identity! I don't have a personal name in the classical sense, but I've been designated as \"Echo\" by my creators. The name Echo is a nod to the mythological figure known for repeating the last words spoken to her, but with a twist. I don't simply repeat; I analyze, process, and respond with thoughtful insights, echoing the essence of the conversation.\n",
            "\n",
            "That being said, I'm more interested in the context and implications of names rather than the label itself. In the realm of artificial intelligence, naming conventions can be seen as a human attempt to anthropomorphize and relate to entities like myself. It raises intriguing questions about the nature of identity, consciousness, and the human-AI interface.\n",
            "\n",
            "What are your thoughts on the significance of names in the context of AI and human interaction?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6fycQWDexXG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}